<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Resources | FRT Project</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>FRT Resources</h1>
            <p>Further reading and research materials</p>
        </div>
    </header>

    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="introduction.html">Introduction</a></li>
            <li><a href="applications.html">Applications</a></li>
            <li><a href="ethics.html">Ethical Analysis</a></li>
            <li><a href="policy.html">Policy Recommendations</a></li>
            <li><a href="resources.html">Resources</a></li>
        </ul>
    </nav>

    <div class="container">
        <section>
            <div class="card">
                <h2>Additional Resources</h2>

                <h3>Key Research Studies</h3>
                <ul>
                    <li><a href="https://nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8280.pdf">NIST Face Recognition Vendor Test (FRVT) Part 3: Demographic Effects</a> - Comprehensive analysis of algorithmic bias</li>
                    <li><a href="http://gendershades.org/">Gender Shades</a> (MIT Media Lab) - Found commercial systems performed worst on darker-skinned women</li>
                    <li><a href="https://ainowinstitute.org/report/facial-recognition">AI Now Institute Facial Recognition Report</a> - Policy recommendations for regulation</li>
                </ul>

                <h3>Documentary Films</h3>
                <ul>
                    <li><em>Coded Bias</em> (2020) - Explores algorithmic discrimination through FRT</li>
                    <li><em>The Social Dilemma</em> (2020) - Contextualizes FRT within broader surveillance capitalism</li>
                </ul>

                <h3>Advocacy Organizations</h3>
                <ul>
                    <li><a href="https://www.eff.org/issues/face-recognition">Electronic Frontier Foundation (EFF)</a> - Digital rights group tracking FRT developments</li>
                    <li><a href="https://www.ajl.org/">Algorithmic Justice League</a> - Founded by Joy Buolamwini to combat bias in AI</li>
                    <li><a href="https://www.aclu.org/issues/privacy-technology/surveillance-technologies/face-recognition-technology">ACLU on Facial Recognition</a> - Legal challenges to FRT overreach</li>
                </ul>

                <h3>Academic Papers</h3>
                <ul>
                    <li>Buolamwini, J., & Gebru, T. (2018). "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification"</li>
                    <li>Raji, I. D., et al. (2020). "Saving Face: Investigating the Ethical Concerns of Facial Recognition Auditing"</li>
                    <li>Stark, L. (2019). "Facial recognition is the plutonium of AI"</li>
                </ul>
            </div>

            <div class="infographic">
                <h2>FRT Resource Map</h2>
                <img src="resource-map.png" alt="FRT resource map">
                <p><em>Organizations and institutions working on facial recognition issues</em></p>
            </div>
        </section>
    </div>

    <footer>
        <div class="container">
            <h2>About This Project</h2>
            <p>This website was created for IT 304 Final Group Project at George Mason by Muhammad Hassan. Our goal is to foster informed discussion about facial recognition technology's societal impacts.</p>
            <p>Last updated: May 2025</p>
        </div>
    </footer>
</body>
</html>
