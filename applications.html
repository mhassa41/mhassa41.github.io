<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FRT Applications | FRT Project</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>Applications of Facial Recognition</h1>
            <p>Real-world uses and their challenges</p>
        </div>
    </header>

    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="introduction.html">Introduction</a></li>
            <li><a href="applications.html">Applications</a></li>
            <li><a href="ethics.html">Ethical Analysis</a></li>
            <li><a href="policy.html">Policy Recommendations</a></li>
            <li><a href="resources.html">Resources</a></li>
        </ul>
    </nav>

    <div class="container">
        <section>
            <div class="card">
                <h2>Real-World Applications & Challenges</h2>
                <p>Facial recognition technology has moved beyond theoretical applications to become embedded in daily life. These case studies highlight both the potential benefits and significant risks.</p>
            </div>

            <div class="case-study">
                <img src="law-enforcement-frt.jpg" alt="Police using facial recognition">
                <div class="case-study-content">
                    <h3>1. Law Enforcement: Crime Prevention or Racial Profiling?</h3>
                    <p><strong>Implementation:</strong> Police departments worldwide use FRT to identify suspects, locate missing persons, and monitor public spaces. In China, authorities have integrated FRT with social credit systems.</p>

                    <p><strong>Documented Problems:</strong></p>
                    <ul>
                        <li><strong>Algorithmic Bias:</strong> MIT and NIST studies found commercial systems had error rates up to 34% higher for dark-skinned women compared to light-skinned men.</li>
                        <li><strong>False Arrests:</strong> Robert Williams was wrongfully detained in Detroit after FRT misidentified him as a shoplifting suspect. The algorithm was trained primarily on white faces.</li>
                        <li><strong>Chilling Effects:</strong> Communities of color report avoiding public spaces due to surveillance concerns, restricting freedom of movement.</li>
                    </ul>

                    <p><strong>Complexity:</strong> While FRT has helped solve crimes (like identifying the Capital Gazette shooter), its unreliability with non-white faces means marginalized communities bear disproportionate harm from false positives.</p>
                </div>
            </div>

            <div class="case-study">
                <div class="case-study-content">
                    <h3>2. Retail & Advertising: Personalized Service or Surveillance Capitalism?</h3>
                    <p><strong>Implementation:</strong> Major retailers use FRT for:</p>
                    <ul>
                        <li>Identifying shoplifters (often with high error rates)</li>
                        <li>Personalized advertising (analyzing customer demographics and reactions)</li>
                        <li>Cashier-less checkout systems</li>
                    </ul>

                    <p><strong>Documented Problems:</strong></p>
                    <ul>
                        <li><strong>Lack of Consent:</strong> Customers are rarely informed when being scanned, violating expectations of privacy in commercial spaces.</li>
                        <li><strong>Data Exploitation:</strong> Facial data collected in stores may be sold to third parties or used to build more comprehensive tracking profiles.</li>
                        <li><strong>Discriminatory Targeting:</strong> Systems may offer different prices or products based on perceived demographics, potentially enabling digital redlining.</li>
                    </ul>
                </div>
                <img src="retail-frt.jpg" alt="Retail facial recognition">
            </div>

            <div class="infographic">
                <h2>Facial Recognition Error Rates by Demographic</h2>
                <img src="frt-error-rates.png" alt="FRT error rates by demographic">
                <p><em>Data visualization demonstrating racial and gender disparities in FRT accuracy</em></p>
            </div>
        </section>
    </div>

    <footer>
        <div class="container">
            <h2>About This Project</h2>
            <p>This website was created for IT 304 Final Group Project at George Mason by Muhammad Hassan, Javier Gethers, Shehzil Ahmed and Ramzy Niori. Our goal is to foster informed discussion about facial recognition technology's societal impacts.</p>
            <p>Last updated: May 2025</p>
        </div>
    </footer>
</body>
</html>